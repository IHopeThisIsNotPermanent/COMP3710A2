{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNAO4WIscctb"
      },
      "source": [
        "# Using the pytorch example for CIFAR10\n",
        "\n",
        "#### Note on downloading the dataset:\n",
        "Downloaded the cifar10 dataset manually using curl, but the code below will download it if it missing from the datasets folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eflGHjUHcctc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import v2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "d = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workers = multiprocessing.cpu_count()-1\n",
        "print(f'Workers: {workers}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehHVtXQth-vA",
        "outputId": "c2e1dc70-397d-48b8-c6f5-1c9cce3985b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workers: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPhAlUCccctd",
        "outputId": "c52b76b1-76f9-4e7a-c4e3-fa96fc90e95f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workers: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 102MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
        "     transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "     transforms.ToTensor()])\n",
        "\n",
        "batch_size = 100\n",
        "workers = multiprocessing.cpu_count()-1\n",
        "print(f'Workers: {workers}')\n",
        "trainset = torchvision.datasets.CIFAR10(root='./datasets', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=workers)\n",
        "testset = torchvision.datasets.CIFAR10(root='./datasets', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=workers)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RO6nx4Aucctd"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(   3, 2**4, 3, padding = 1)\n",
        "        self.conv2 = nn.Conv2d(2**4, 2**5, 3, padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(2**5, 2**6, 3, padding = 1)\n",
        "        self.conv4 = nn.Conv2d(2**6, 2**7, 3, padding = 1)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(2**7, 2**8, 3, padding = 1)\n",
        "        self.conv6 = nn.Conv2d(2**8, 2**9, 3, padding = 1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(2**4)\n",
        "        self.bn2 = nn.BatchNorm2d(2**6)\n",
        "        self.bn3 = nn.BatchNorm2d(2**8)\n",
        "\n",
        "        self.dropout = nn.Dropout2d(0.2)\n",
        "        self.shortcut1 = nn.Sequential(nn.Conv2d(3, 2**5, kernel_size=3, padding = 1, bias=False),\n",
        "                                       nn.BatchNorm2d(2**5))\n",
        "        self.shortcut2 = nn.Sequential(nn.Conv2d(2**5, 2**7, kernel_size=3, padding = 1, bias=False),\n",
        "                                       nn.BatchNorm2d(2**7))\n",
        "        self.shortcut3 = nn.Sequential(nn.Conv2d(2**7, 2**9, kernel_size=3, padding = 1, bias=False),\n",
        "                                       nn.BatchNorm2d(2**9))\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc0 = nn.Linear(2**13, 2**13)\n",
        "        self.fc1 = nn.Linear(2**13, 2**12)\n",
        "        self.fc2 = nn.Linear(2**12, 2**11)\n",
        "        self.fc3 = nn.Linear(2**11, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.conv2(out)\n",
        "        out += self.shortcut1(x)\n",
        "        out = F.relu(out)\n",
        "        x = self.pool2(out)\n",
        "\n",
        "        out = F.relu(self.bn2(self.conv3(x)))\n",
        "        out = self.conv4(out)\n",
        "        out += self.shortcut2(x)\n",
        "        out = F.relu(out)\n",
        "        x = self.pool2(out)\n",
        "\n",
        "        out = F.relu(self.bn3(self.conv5(x)))\n",
        "        out = self.conv6(out)\n",
        "        out += self.shortcut3(x)\n",
        "        out = F.relu(out)\n",
        "        x = self.pool2(out)\n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc0(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tUXOvdQtccte",
        "outputId": "a059aadb-e1be-487d-b1c4-5f5dcc67d475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:1535: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, Loss: 0.67, time: 12.28s\n",
            "epoch: 1, Loss: 0.63, time: 24.51s\n",
            "epoch: 2, Loss: 0.61, time: 36.96s\n",
            "epoch: 3, Loss: 0.59, time: 49.18s\n",
            "epoch: 4, Loss: 0.58, time: 61.53s\n",
            "Accuracy: 53.38, Loss: 0.57, time: 75.81s\n",
            "epoch: 5, Loss: 0.57, time: 75.81s\n",
            "epoch: 6, Loss: 0.56, time: 88.07s\n",
            "epoch: 7, Loss: 0.55, time: 100.5s\n",
            "epoch: 8, Loss: 0.55, time: 112.91s\n",
            "epoch: 9, Loss: 0.54, time: 125.18s\n",
            "epoch: 10, Loss: 0.53, time: 137.58s\n",
            "epoch: 11, Loss: 0.53, time: 149.8s\n",
            "epoch: 12, Loss: 0.52, time: 162.15s\n",
            "epoch: 13, Loss: 0.51, time: 174.31s\n",
            "epoch: 14, Loss: 0.52, time: 186.58s\n",
            "Accuracy: 64.65, Loss: 0.5, time: 200.93s\n",
            "epoch: 15, Loss: 0.5, time: 200.93s\n",
            "epoch: 16, Loss: 0.51, time: 213.31s\n",
            "epoch: 17, Loss: 0.51, time: 225.78s\n",
            "epoch: 18, Loss: 0.5, time: 238.12s\n",
            "epoch: 19, Loss: 0.5, time: 250.47s\n",
            "epoch: 20, Loss: 0.49, time: 262.85s\n",
            "epoch: 21, Loss: 0.5, time: 275.16s\n",
            "epoch: 22, Loss: 0.49, time: 287.48s\n",
            "epoch: 23, Loss: 0.49, time: 299.6s\n",
            "epoch: 24, Loss: 0.48, time: 311.91s\n",
            "Accuracy: 70.64, Loss: 0.48, time: 326.11s\n",
            "epoch: 25, Loss: 0.48, time: 326.11s\n",
            "epoch: 26, Loss: 0.48, time: 338.27s\n",
            "epoch: 27, Loss: 0.48, time: 350.66s\n",
            "epoch: 28, Loss: 0.47, time: 363.01s\n",
            "epoch: 29, Loss: 0.48, time: 375.26s\n",
            "epoch: 30, Loss: 0.47, time: 387.62s\n",
            "epoch: 31, Loss: 0.47, time: 400.5s\n",
            "epoch: 32, Loss: 0.46, time: 412.6s\n",
            "epoch: 33, Loss: 0.46, time: 424.61s\n",
            "epoch: 34, Loss: 0.47, time: 436.86s\n",
            "Accuracy: 74.51, Loss: 0.46, time: 451.2s\n",
            "epoch: 35, Loss: 0.46, time: 451.2s\n",
            "epoch: 36, Loss: 0.46, time: 463.41s\n",
            "epoch: 37, Loss: 0.46, time: 475.63s\n",
            "epoch: 38, Loss: 0.46, time: 488.14s\n",
            "epoch: 39, Loss: 0.45, time: 500.54s\n",
            "epoch: 40, Loss: 0.45, time: 513.01s\n",
            "epoch: 41, Loss: 0.45, time: 525.46s\n",
            "epoch: 42, Loss: 0.45, time: 537.84s\n",
            "epoch: 43, Loss: 0.45, time: 550.21s\n",
            "epoch: 44, Loss: 0.45, time: 562.68s\n",
            "Accuracy: 76.28, Loss: 0.45, time: 576.86s\n",
            "epoch: 45, Loss: 0.45, time: 576.86s\n",
            "epoch: 46, Loss: 0.44, time: 589.32s\n",
            "epoch: 47, Loss: 0.44, time: 601.57s\n",
            "epoch: 48, Loss: 0.45, time: 613.9s\n",
            "epoch: 49, Loss: 0.44, time: 626.14s\n",
            "epoch: 50, Loss: 0.44, time: 638.5s\n",
            "epoch: 51, Loss: 0.44, time: 650.73s\n",
            "epoch: 52, Loss: 0.45, time: 662.96s\n",
            "epoch: 53, Loss: 0.44, time: 675.42s\n",
            "epoch: 54, Loss: 0.44, time: 687.76s\n",
            "Accuracy: 78.0, Loss: 0.44, time: 702.02s\n",
            "epoch: 55, Loss: 0.44, time: 702.02s\n",
            "epoch: 56, Loss: 0.44, time: 714.4s\n",
            "epoch: 57, Loss: 0.43, time: 726.77s\n",
            "epoch: 58, Loss: 0.43, time: 739.16s\n",
            "epoch: 59, Loss: 0.43, time: 751.4s\n",
            "epoch: 60, Loss: 0.43, time: 763.7s\n",
            "epoch: 61, Loss: 0.43, time: 775.98s\n",
            "epoch: 62, Loss: 0.43, time: 788.35s\n",
            "epoch: 63, Loss: 0.43, time: 800.7s\n",
            "epoch: 64, Loss: 0.43, time: 813.08s\n",
            "Accuracy: 78.6, Loss: 0.42, time: 827.33s\n",
            "epoch: 65, Loss: 0.42, time: 827.33s\n",
            "epoch: 66, Loss: 0.43, time: 839.67s\n",
            "epoch: 67, Loss: 0.43, time: 852.04s\n",
            "epoch: 68, Loss: 0.42, time: 864.43s\n",
            "epoch: 69, Loss: 0.43, time: 876.75s\n",
            "epoch: 70, Loss: 0.43, time: 889.13s\n",
            "epoch: 71, Loss: 0.43, time: 901.36s\n",
            "epoch: 72, Loss: 0.43, time: 913.63s\n",
            "epoch: 73, Loss: 0.42, time: 926.09s\n",
            "epoch: 74, Loss: 0.42, time: 938.41s\n",
            "Accuracy: 80.55, Loss: 0.43, time: 952.74s\n",
            "epoch: 75, Loss: 0.43, time: 952.74s\n",
            "epoch: 76, Loss: 0.42, time: 965.05s\n",
            "epoch: 77, Loss: 0.42, time: 977.37s\n",
            "epoch: 78, Loss: 0.42, time: 989.59s\n",
            "epoch: 79, Loss: 0.42, time: 1001.83s\n",
            "epoch: 80, Loss: 0.42, time: 1014.13s\n",
            "epoch: 81, Loss: 0.42, time: 1026.37s\n",
            "epoch: 82, Loss: 0.42, time: 1038.67s\n",
            "epoch: 83, Loss: 0.41, time: 1051.1s\n",
            "epoch: 84, Loss: 0.41, time: 1063.3s\n",
            "Accuracy: 81.69, Loss: 0.42, time: 1077.46s\n",
            "epoch: 85, Loss: 0.42, time: 1077.46s\n",
            "epoch: 86, Loss: 0.41, time: 1089.77s\n",
            "epoch: 87, Loss: 0.42, time: 1102.16s\n",
            "epoch: 88, Loss: 0.42, time: 1114.66s\n",
            "epoch: 89, Loss: 0.41, time: 1127.04s\n",
            "epoch: 90, Loss: 0.41, time: 1139.29s\n",
            "epoch: 91, Loss: 0.42, time: 1151.59s\n",
            "epoch: 92, Loss: 0.41, time: 1163.96s\n",
            "epoch: 93, Loss: 0.4, time: 1176.21s\n",
            "epoch: 94, Loss: 0.4, time: 1188.58s\n",
            "Accuracy: 82.08, Loss: 0.41, time: 1202.81s\n",
            "epoch: 95, Loss: 0.41, time: 1202.81s\n",
            "epoch: 96, Loss: 0.41, time: 1215.23s\n",
            "epoch: 97, Loss: 0.41, time: 1227.62s\n",
            "epoch: 98, Loss: 0.4, time: 1240.11s\n",
            "epoch: 99, Loss: 0.42, time: 1252.47s\n",
            "epoch: 100, Loss: 0.4, time: 1264.87s\n",
            "epoch: 101, Loss: 0.41, time: 1277.04s\n",
            "epoch: 102, Loss: 0.41, time: 1289.33s\n",
            "epoch: 103, Loss: 0.4, time: 1301.65s\n",
            "epoch: 104, Loss: 0.41, time: 1314.03s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1835303197.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutmix_or_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss_list = []\n",
        "\n",
        "cutmix = v2.CutMix(num_classes=10)\n",
        "mixup = v2.MixUp(num_classes=10)\n",
        "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])\n",
        "\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.RandomCrop(32, padding=4),\n",
        "     transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
        "     transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.15),\n",
        "     transforms.ToTensor()])\n",
        "\n",
        "batch_size = 80\n",
        "workers = multiprocessing.cpu_count()-2\n",
        "trainset = torchvision.datasets.CIFAR10(root='./datasets', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=workers)\n",
        "testset = torchvision.datasets.CIFAR10(root='./datasets', train=False,\n",
        "                                      download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                        shuffle=False, num_workers=workers)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "          'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "net = Net().to(d)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "#lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=10,min_lr=0.00001)\n",
        "import time\n",
        "t1 = time.time()\n",
        "correct, total = 0,1\n",
        "for epoch in range(300):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        data = cutmix_or_mixup(data[0], data[1])\n",
        "        inputs, labels = data[0].to(d), data[1].to(d)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs).to(d)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    if epoch % 10 == 5:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in testloader:\n",
        "                images, labels = data[0].to(d), data[1].to(d)\n",
        "                outputs = net(images).to(d)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        print(f'Accuracy: {round(100.0 * float(correct / total),2)}, Loss: {round(running_loss / 2000,2)}, time: {round(time.time()-t1, 2)}s')\n",
        "\n",
        "    #lr_scheduler.step(running_loss / i)\n",
        "    print(f'epoch: {epoch}, Loss: {round(running_loss / 2000,2)}, time: {round(time.time()-t1, 2)}s')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YiNbBNZccte",
        "outputId": "8af89c5a-af8a-45e4-e76d-c0d35b68234d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 73 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC66EqY2ccte"
      },
      "source": [
        "# Failed experiments\n",
        "\n",
        "#### Experiment 1\n",
        "\n",
        "```python\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3, padding = 1)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, padding = 1)\n",
        "        self.conv4 = nn.Conv2d(32, 64, 3, padding = 1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.pool4 = nn.MaxPool2d(4, 4)\n",
        "        self.fc1 = nn.Linear(64, 30)\n",
        "        self.fc2 = nn.Linear(30, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool2(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = self.pool2(F.relu(self.conv3(x)))\n",
        "        x = self.pool4(F.relu(self.conv4(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "```\n",
        "After 10 epochs got to 65% on test. 16mins on cpu.\n",
        "After 20 epochs got to 66% on test. 23mins on cpu.\n",
        "\n",
        "#### Test 2\n",
        "\n",
        "I made it bigger, and got no decrease in computation speed, but now in 10 epochs i got 73%! the loss began platouing at the end anyway, so I dont think more iterations will increase the test test by that much.\n",
        "```python\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding = 1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding = 1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.pool4 = nn.MaxPool2d(4, 4)\n",
        "        self.fc1 = nn.Linear(128, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool2(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = self.pool2(F.relu(self.conv3(x)))\n",
        "        x = self.pool4(F.relu(self.conv4(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "```\n",
        "\n",
        "#### Test 3\n",
        "\n",
        "I Added more linear layers at the end, and ran it for 20 epochs. Interestingly this did nothing whatsoever, still got a test accuracy of 73%, thought this time ~30 minutes on cpu.\n",
        "\n",
        "#### Test4 - Have been getting the best results on the bigger models, so now to compensate for overfitting, I'll add some data augmentation techniques.\n",
        "\n",
        "this got it up to 83% Which is nice, but not quite there.\n",
        "\n",
        "#### Test5 - you dont actually need to max pool every conv layer.\n",
        "\n",
        "This lets you add more conv layers cause you dont reduce the size of the image till you cant do convolutions\n",
        "\n",
        "```python\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(   3, 2**4, 3, padding = 1)\n",
        "        self.conv2 = nn.Conv2d(2**4, 2**5, 3, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(2**5, 2**6, 3, padding = 1)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(2**6, 2**7, 3, padding = 1)\n",
        "        self.conv5 = nn.Conv2d(2**7, 2**8, 3, padding = 1)\n",
        "        self.conv6 = nn.Conv2d(2**8, 2**9, 3, padding = 1)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(2**13, 2**12)\n",
        "        self.fc2 = nn.Linear(2**12, 2**11)\n",
        "        self.fc3 = nn.Linear(2**11, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))\n",
        "\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net().to(d)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.0004, momentum=0.9)\n",
        "```\n",
        "Got up to 77% after 20 epochs, ~1hr on google colab.\n",
        "\n",
        "#### Added batch normalization, and increased learning rate\n",
        "\n",
        "Got up to 86% after 23 epochs, ~1.5 hours on google colab, inctreased batch size to 100 and got %91 after 90 epochs, 29mins.\n",
        "\n",
        "```python\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(   3, 2**4, 3, padding = 1)\n",
        "        self.conv2 = nn.Conv2d(2**4, 2**5, 3, padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(2**5, 2**6, 3, padding = 1)\n",
        "        self.conv4 = nn.Conv2d(2**6, 2**7, 3, padding = 1)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(2**7, 2**8, 3, padding = 1)\n",
        "        self.conv6 = nn.Conv2d(2**8, 2**9, 3, padding = 1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(2**4)\n",
        "        self.bn2 = nn.BatchNorm2d(2**6)\n",
        "        self.bn3 = nn.BatchNorm2d(2**8)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(2**13, 2**12)\n",
        "        self.fc2 = nn.Linear(2**12, 2**11)\n",
        "        self.fc3 = nn.Linear(2**11, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.conv2(x))\n",
        "\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x))\n",
        "\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv5(x)))\n",
        "        x = F.relu(self.conv6(x))\n",
        "\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "d = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "# Download the data, if not already on disk and load it as numpy arrays\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "\n",
        "X = lfw_people.images\n",
        "Y = lfw_people.target\n",
        "# Verify the value range of X_train. No normalization is necessary in this case,\n",
        "# as the input values already fall within the range of 0.0 to 1.0.\n",
        "print(\"X_min:\",X.min(),\"X_train_max:\", X.max())\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
        "X_train = X_train[:, np.newaxis, :, :]\n",
        "X_test = X_test[:, np.newaxis, :, :]\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "\n",
        "class zipped_ds:\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, i):\n",
        "        return self.data[i], self.labels[i]\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "batch_size = 8\n",
        "trainloader = torch.utils.data.DataLoader(zipped_ds(X_train, y_train), batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(zipped_ds(X_test, y_test), batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQfFbdPHA94q",
        "outputId": "73eecefe-1e5a-49eb-dcb8-ef3b286b7f89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_min: 0.0 X_train_max: 1.0\n",
            "X_train shape: (966, 1, 50, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(   1, 32, 3, padding = 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(64, 96, 3, padding = 1)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(2304, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net().to(d)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "WF1xNtzvBCGS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(d), data[1].to(d)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs).to(d)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(d), data[1].to(d)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'epoch: {epoch}, loss: {round(running_loss / i,2)}, Accuracy: {100 * correct // total} %')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xUDYjuvBE1R",
        "outputId": "a2e2314f-1c74-40e5-fa8d-4348a85aae65"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, loss: 1.77, Accuracy: 45 %\n",
            "epoch: 1, loss: 1.73, Accuracy: 45 %\n",
            "epoch: 2, loss: 1.72, Accuracy: 45 %\n",
            "epoch: 3, loss: 1.72, Accuracy: 45 %\n",
            "epoch: 4, loss: 1.68, Accuracy: 46 %\n",
            "epoch: 5, loss: 1.56, Accuracy: 47 %\n",
            "epoch: 6, loss: 1.41, Accuracy: 59 %\n",
            "epoch: 7, loss: 1.12, Accuracy: 70 %\n",
            "epoch: 8, loss: 0.9, Accuracy: 77 %\n",
            "epoch: 9, loss: 0.67, Accuracy: 73 %\n",
            "Finished Training\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}