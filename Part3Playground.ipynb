{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the pytorch example for CIFAR10\n",
    "\n",
    "#### Note on downloading the dataset:\n",
    "Downloaded the cifar10 dataset manually using curl, but the code below will download it if it missing from the datasets folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "d = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./datasets', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./datasets', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.pool4 = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(64, 30)\n",
    "        self.fc2 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool2(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool2(F.relu(self.conv3(x)))\n",
    "        x = self.pool4(F.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.256\n",
      "[1,  4000] loss: 1.989\n",
      "[1,  6000] loss: 1.777\n",
      "[1,  8000] loss: 1.679\n",
      "[1, 10000] loss: 1.584\n",
      "[1, 12000] loss: 1.526\n",
      "[2,  2000] loss: 1.466\n",
      "[2,  4000] loss: 1.409\n",
      "[2,  6000] loss: 1.353\n",
      "[2,  8000] loss: 1.356\n",
      "[2, 10000] loss: 1.299\n",
      "[2, 12000] loss: 1.293\n",
      "[3,  2000] loss: 1.237\n",
      "[3,  4000] loss: 1.210\n",
      "[3,  6000] loss: 1.186\n",
      "[3,  8000] loss: 1.161\n",
      "[3, 10000] loss: 1.179\n",
      "[3, 12000] loss: 1.167\n",
      "[4,  2000] loss: 1.101\n",
      "[4,  4000] loss: 1.085\n",
      "[4,  6000] loss: 1.096\n",
      "[4,  8000] loss: 1.068\n",
      "[4, 10000] loss: 1.077\n",
      "[4, 12000] loss: 1.055\n",
      "[5,  2000] loss: 1.030\n",
      "[5,  4000] loss: 1.012\n",
      "[5,  6000] loss: 1.010\n",
      "[5,  8000] loss: 1.004\n",
      "[5, 10000] loss: 1.014\n",
      "[5, 12000] loss: 1.020\n",
      "[6,  2000] loss: 0.961\n",
      "[6,  4000] loss: 0.960\n",
      "[6,  6000] loss: 0.970\n",
      "[6,  8000] loss: 0.958\n",
      "[6, 10000] loss: 0.964\n",
      "[6, 12000] loss: 0.985\n",
      "[7,  2000] loss: 0.920\n",
      "[7,  4000] loss: 0.920\n",
      "[7,  6000] loss: 0.916\n",
      "[7,  8000] loss: 0.941\n",
      "[7, 10000] loss: 0.932\n",
      "[7, 12000] loss: 0.958\n",
      "[8,  2000] loss: 0.884\n",
      "[8,  4000] loss: 0.921\n",
      "[8,  6000] loss: 0.895\n",
      "[8,  8000] loss: 0.925\n",
      "[8, 10000] loss: 0.912\n",
      "[8, 12000] loss: 0.898\n",
      "[9,  2000] loss: 0.863\n",
      "[9,  4000] loss: 0.863\n",
      "[9,  6000] loss: 0.897\n",
      "[9,  8000] loss: 0.891\n",
      "[9, 10000] loss: 0.865\n",
      "[9, 12000] loss: 0.891\n",
      "[10,  2000] loss: 0.832\n",
      "[10,  4000] loss: 0.846\n",
      "[10,  6000] loss: 0.859\n",
      "[10,  8000] loss: 0.878\n",
      "[10, 10000] loss: 0.881\n",
      "[10, 12000] loss: 0.888\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(d), data[1].to(d)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs).to(d)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  \n",
    "            loss_list.append(running_loss / 2000)\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 65 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failed experiments\n",
    "\n",
    "#### Experiment 1\n",
    "\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.pool4 = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(64, 30)\n",
    "        self.fc2 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool2(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool2(F.relu(self.conv3(x)))\n",
    "        x = self.pool4(F.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "```\n",
    "After 10 epochs got to 65% on test. 16mins on gpu\n",
    "\n",
    "#### Test 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
